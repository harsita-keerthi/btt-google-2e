{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E99VlROCUoAa",
        "outputId": "2d854dba-2c96-4740-ad65-907b7b9e1dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EKjuaUKVtNs",
        "outputId": "a79fb725-dc04-4ff0-c4f9-5778c9190e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers datasets torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNU6YlcnVSWV",
        "outputId": "6d76be8b-2322-4e2c-ca93-71db61582c18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/google-2e')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AkLNtkLEWPhX",
        "outputId": "be29738e-86bd-4b61-b463-cf2a4cb6b4d9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 17500,\n  \"fields\": [\n    {\n      \"column\": \"Query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17500,\n        \"samples\": [\n          \"Is Mount McKinley the highest elevation in alaska ?\",\n          \"Tumor of the liver is called ?\",\n          \"What are the diameter of planet earth ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Well-Formed Rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3793980444035244,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.0,\n          0.2,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-67ef1e37-c8f7-4ec3-95af-4818b54a4fc8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>Well-Formed Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The European Union includes how many ?</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are Mia Hamms accomplishment ?</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Which form of government is still in place in ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>When was the canal de panama built ?</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What color is the black box on commercial aero...</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17495</th>\n",
              "      <td>What is the youngest college graduate ?</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17496</th>\n",
              "      <td>Pros and cons of making dams ?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17497</th>\n",
              "      <td>Life and story of jose ma panganiban ?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17498</th>\n",
              "      <td>How do you apply for a super delegate position ?</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17499</th>\n",
              "      <td>What is the incubation period for a giant tort...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17500 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67ef1e37-c8f7-4ec3-95af-4818b54a4fc8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67ef1e37-c8f7-4ec3-95af-4818b54a4fc8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67ef1e37-c8f7-4ec3-95af-4818b54a4fc8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c0d9913-8fac-43e7-b91b-f17cc070c35e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c0d9913-8fac-43e7-b91b-f17cc070c35e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c0d9913-8fac-43e7-b91b-f17cc070c35e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f7df079e-e451-4808-a2d0-0965303e25c0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f7df079e-e451-4808-a2d0-0965303e25c0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                   Query  Well-Formed Rank\n",
              "0                 The European Union includes how many ?               0.2\n",
              "1                    What are Mia Hamms accomplishment ?               0.4\n",
              "2      Which form of government is still in place in ...               1.0\n",
              "3                   When was the canal de panama built ?               0.8\n",
              "4      What color is the black box on commercial aero...               0.6\n",
              "...                                                  ...               ...\n",
              "17495            What is the youngest college graduate ?               0.4\n",
              "17496                     Pros and cons of making dams ?               0.0\n",
              "17497             Life and story of jose ma panganiban ?               0.0\n",
              "17498   How do you apply for a super delegate position ?               1.0\n",
              "17499  What is the incubation period for a giant tort...               1.0\n",
              "\n",
              "[17500 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv('train.tsv', sep = '\\t', header = None)\n",
        "dev_df = pd.read_csv('dev.tsv', sep = '\\t', header = None)\n",
        "test_df = pd.read_csv('test.tsv', sep = '\\t', header = None)\n",
        "\n",
        "train_df.columns = ['Query', 'Well-Formed Rank']\n",
        "dev_df.columns = ['Query', 'Well-Formed Rank']\n",
        "test_df.columns = ['Query', 'Well-Formed Rank']\n",
        "\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "pUQa3i7QmvAe",
        "outputId": "abfd5493-4c21-4472-fc2e-76a1ea487ec8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Query</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Well-Formed Rank</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "Query               0\n",
              "Well-Formed Rank    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.apply(lambda x: x.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "eVqrl9QlnFu4",
        "outputId": "7b83d763-ed87-4084-a53f-d0e8a26d9fc2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"filtered_train\",\n  \"rows\": 8836,\n  \"fields\": [\n    {\n      \"column\": \"Query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8836,\n        \"samples\": [\n          \"When did maragret thatcher die \",\n          \"How much is a quarter from 1940 \",\n          \"What is a multilateral link \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Well-Formed Rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16069727648503054,\n        \"min\": 0.5,\n        \"max\": 1.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.0,\n          0.8,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "filtered_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e9131df7-182a-49c9-b24a-cf5a51fc3129\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>Well-Formed Rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Which form of government is still in place in ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>When was the canal de panama built</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What color is the black box on commercial aero...</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How did samoans come into samoa</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What is the value of military payment certific...</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17491</th>\n",
              "      <td>What are some consequences of cyber bullying</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17492</th>\n",
              "      <td>What are the 4 major climate types of northern...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17494</th>\n",
              "      <td>How does a sound wave transmit matter</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17498</th>\n",
              "      <td>How do you apply for a super delegate position</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17499</th>\n",
              "      <td>What is the incubation period for a giant tort...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8836 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9131df7-182a-49c9-b24a-cf5a51fc3129')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e9131df7-182a-49c9-b24a-cf5a51fc3129 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e9131df7-182a-49c9-b24a-cf5a51fc3129');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0e0f765c-768c-477e-ab47-22f5ef4471ee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e0f765c-768c-477e-ab47-22f5ef4471ee')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0e0f765c-768c-477e-ab47-22f5ef4471ee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_12a846ec-93d6-4bd9-bc49-048534ea9641\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('filtered_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_12a846ec-93d6-4bd9-bc49-048534ea9641 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('filtered_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                   Query  Well-Formed Rank\n",
              "2      Which form of government is still in place in ...               1.0\n",
              "3                    When was the canal de panama built                0.8\n",
              "4      What color is the black box on commercial aero...               0.6\n",
              "6                       How did samoans come into samoa                0.8\n",
              "9      What is the value of military payment certific...               0.8\n",
              "...                                                  ...               ...\n",
              "17491      What are some consequences of cyber bullying                1.0\n",
              "17492  What are the 4 major climate types of northern...               1.0\n",
              "17494             How does a sound wave transmit matter                1.0\n",
              "17498    How do you apply for a super delegate position                1.0\n",
              "17499  What is the incubation period for a giant tort...               1.0\n",
              "\n",
              "[8836 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['Query'] = train_df['Query'].str.rstrip('?')\n",
        "dev_df['Query'] = dev_df['Query'].str.rstrip('?')\n",
        "test_df['Query'] = test_df['Query'].str.rstrip('?')\n",
        "\n",
        "filtered_train = train_df[train_df['Well-Formed Rank']>=0.5]\n",
        "filtered_dev = dev_df[dev_df['Well-Formed Rank']>=0.5]\n",
        "filtered_test = test_df[test_df['Well-Formed Rank']>=0.5]\n",
        "\n",
        "filtered_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "collapsed": true,
        "id": "IwwPoA5jQqq6",
        "outputId": "6df8ddea-97bc-4727-c4dd-20b719b3f34a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6627' max='6627' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6627/6627 09:52, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.730800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.512400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.349600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>4.302700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>3.911400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>3.621500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>3.560800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>3.578800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>3.496500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>3.175900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>3.181400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>3.190300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>3.186100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('./gpt_model_save1/tokenizer_config.json',\n",
              " './gpt_model_save1/special_tokens_map.json',\n",
              " './gpt_model_save1/vocab.json',\n",
              " './gpt_model_save1/merges.txt',\n",
              " './gpt_model_save1/added_tokens.json')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finetune gpt model\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.to(device)\n",
        "\n",
        "# prepare datasets\n",
        "train_queries = filtered_train['Query'].tolist()\n",
        "dev_queries = filtered_dev['Query'].tolist()\n",
        "\n",
        "# we pad labels to train for autocompletion\n",
        "def prepare_inputs_and_labels(queries, n): # i think the issue is here, the model keeps suggesting n words and doesn't know where to stop --> suggest a still incomplete query\n",
        "    inputs = []\n",
        "    labels = []\n",
        "\n",
        "    for query in queries:\n",
        "        input_ids = tokenizer(query, truncation=True, return_tensors='pt')['input_ids'][0]\n",
        "        inputs.append(tokenizer.decode(input_ids[:-n], skip_special_tokens=True))\n",
        "        labels.append(tokenizer.decode(input_ids, skip_special_tokens=True))\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "inputs_train, labels_train = prepare_inputs_and_labels(train_queries, n=3)\n",
        "inputs_dev, labels_dev = prepare_inputs_and_labels(dev_queries, n=3)\n",
        "\n",
        "tokenized_train_cleaned = tokenizer(inputs_train, padding=True, truncation=True, return_tensors='pt')\n",
        "tokenized_dev_cleaned = tokenizer(inputs_dev, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "train_labels = torch.full(tokenized_train_cleaned['input_ids'].shape, -100)\n",
        "for i in range(len(labels_train)):\n",
        "    label_ids = tokenizer(labels_train[i], truncation=True, return_tensors='pt')['input_ids'][0]\n",
        "    train_labels[i, :label_ids.shape[0]] = label_ids[:tokenized_train_cleaned['input_ids'].shape[1]]\n",
        "\n",
        "dev_labels = torch.full(tokenized_dev_cleaned['input_ids'].shape, -100)\n",
        "for i in range(len(labels_dev)):\n",
        "    label_ids = tokenizer(labels_dev[i], truncation=True, return_tensors='pt')['input_ids'][0]\n",
        "    dev_labels[i, :label_ids.shape[0]] = label_ids[:tokenized_dev_cleaned['input_ids'].shape[1]]\n",
        "\n",
        "tokenized_train_cleaned['labels'] = train_labels\n",
        "tokenized_dev_cleaned['labels'] = dev_labels\n",
        "\n",
        "# create dataset\n",
        "class QueryDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = QueryDataset(tokenized_train_cleaned)\n",
        "dev_dataset = QueryDataset(tokenized_dev_cleaned)\n",
        "\n",
        "# train model on dataset (takes 5-10 min w/ gpu)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    logging_dir='./logs',\n",
        "    report_to='none',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# save finetuned model\n",
        "model.save_pretrained('./gpt_model_save1')\n",
        "tokenizer.save_pretrained('./gpt_model_save1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBKA6NgGXgOi",
        "outputId": "7e9b6d07-87c4-46db-ac23-a939d70a2c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input (Incomplete query): Interesting facts\n",
            "Full query: Interesting facts about Egypt \n",
            "Completion: Interesting facts about the nazi 's control of\n",
            "\n",
            "Input (Incomplete query): What is thais in phuket\n",
            "Full query: What is thais in phuket famous for \n",
            "Completion: What is thais in phuket and what is their capital city of ph\n",
            "\n",
            "Input (Incomplete query): What places have the olig\n",
            "Full query: What places have the oligarchy government \n",
            "Completion: What places have the oligarchy structure in spain and what are\n",
            "\n",
            "Input (Incomplete query): Where is the radiator fan relay located at 97\n",
            "Full query: Where is the radiator fan relay located at 97 voyager \n",
            "Completion: Where is the radiator fan relay located at 97 ywtr jr xbl z\n",
            "\n",
            "Input (Incomplete query): When was the first\n",
            "Full query: When was the first helicopters built \n",
            "Completion: When was the first computer made after being invented by the Chinese\n",
            "\n",
            "Input (Incomplete query): Where is atp synthesized\n",
            "Full query: Where is atp synthesized and stored \n",
            "Completion: Where is atp synthesized and its location used for a medical imaging\n",
            "\n",
            "Input (Incomplete query): How much chemical engineers\n",
            "Full query: How much chemical engineers are paid \n",
            "Completion: How much chemical engineers make an hour in Berkeley CA when they\n",
            "\n",
            "Input (Incomplete query): What diease did jonh travoltas\n",
            "Full query: What diease did jonh travoltas son have \n",
            "Completion: What diease did jonh travoltas invent to make his famous work reversible on\n",
            "\n",
            "Input (Incomplete query): Give at least two diffrent descrptions of\n",
            "Full query: Give at least two diffrent descrptions of relative location \n",
            "Completion: Give at least two diffrent descrptions of the following rule in a given application for\n",
            "\n",
            "Input (Incomplete query): What day of Diwali\n",
            "Full query: What day of Diwali in 1980 \n",
            "Completion: What day of Diwali did Ramesh d'Ital\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# test model\n",
        "# load in model\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "# model = model.to(device)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('./gpt_model_save1')\n",
        "model = GPT2LMHeadModel.from_pretrained('./gpt_model_save1')\n",
        "model = model.to(device)\n",
        "test_queries = test_df['Query'][:10].tolist()\n",
        "n = 3\n",
        "\n",
        "for query in test_queries:\n",
        "\n",
        "    input_ids_full = tokenizer(query, return_tensors='pt')\n",
        "\n",
        "    # get the incomplete input by removing the last n tokens\n",
        "    input_ids = input_ids_full['input_ids'][0][:-n].unsqueeze(0)\n",
        "    attention_mask = input_ids_full['attention_mask'][:, :-n]\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        max_length=input_ids.shape[1] + n + 5,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=1.0,\n",
        "        repetition_penalty=1.2\n",
        "    )\n",
        "\n",
        "    predicted_completion = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"Input (Incomplete query): {tokenizer.decode(input_ids[0], skip_special_tokens=True)}\")\n",
        "    print(f\"Full query: {query}\")\n",
        "    print(f\"Completion: {predicted_completion}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRWHVABykULW"
      },
      "source": [
        "# Vanessa's updated version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "beyf5Vn0khZE",
        "outputId": "bbaa27ce-5d29-48cd-df7e-391532d67734"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2209' max='2209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2209/2209 03:15, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.727300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.504600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.346200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>4.317100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "('./gpt_model_save2/tokenizer_config.json',\n",
              " './gpt_model_save2/special_tokens_map.json',\n",
              " './gpt_model_save2/vocab.json',\n",
              " './gpt_model_save2/merges.txt',\n",
              " './gpt_model_save2/added_tokens.json')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.to(device)\n",
        "\n",
        "# prepare datasets\n",
        "train_queries = filtered_train['Query'].tolist()\n",
        "dev_queries = filtered_dev['Query'].tolist()\n",
        "\n",
        "# we pad labels to train for autocompletion\n",
        "def prepare_inputs_and_labels(queries, n):\n",
        "    inputs = []\n",
        "    labels = []\n",
        "\n",
        "    for query in queries:\n",
        "        input_ids = tokenizer(query, truncation=True, return_tensors='pt')['input_ids'][0]\n",
        "        inputs.append(tokenizer.decode(input_ids[:-n], skip_special_tokens=True))\n",
        "        labels.append(tokenizer.decode(input_ids, skip_special_tokens=True))\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "inputs_train, labels_train = prepare_inputs_and_labels(train_queries, n=3)\n",
        "inputs_dev, labels_dev = prepare_inputs_and_labels(dev_queries, n=3)\n",
        "\n",
        "tokenized_train_cleaned = tokenizer(inputs_train, padding=True, truncation=True, return_tensors='pt')\n",
        "tokenized_dev_cleaned = tokenizer(inputs_dev, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "train_labels = torch.full(tokenized_train_cleaned['input_ids'].shape, -100)\n",
        "for i in range(len(labels_train)):\n",
        "    label_ids = tokenizer(labels_train[i], truncation=True, return_tensors='pt')['input_ids'][0]\n",
        "    train_labels[i, :label_ids.shape[0]] = label_ids[:tokenized_train_cleaned['input_ids'].shape[1]]\n",
        "\n",
        "dev_labels = torch.full(tokenized_dev_cleaned['input_ids'].shape, -100)\n",
        "for i in range(len(labels_dev)):\n",
        "    label_ids = tokenizer(labels_dev[i], truncation=True, return_tensors='pt')['input_ids'][0]\n",
        "    dev_labels[i, :label_ids.shape[0]] = label_ids[:tokenized_dev_cleaned['input_ids'].shape[1]]\n",
        "\n",
        "tokenized_train_cleaned['labels'] = train_labels\n",
        "tokenized_dev_cleaned['labels'] = dev_labels\n",
        "\n",
        "# create dataset\n",
        "class QueryDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = QueryDataset(tokenized_train_cleaned)\n",
        "dev_dataset = QueryDataset(tokenized_dev_cleaned)\n",
        "\n",
        "# train model on dataset (takes 5-10 min w/ gpu)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=1, # VH: reduced epoch\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    logging_dir='./logs',\n",
        "    report_to='none',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=dev_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# save finetuned model\n",
        "model.save_pretrained('./gpt_model_save2')\n",
        "tokenizer.save_pretrained('./gpt_model_save2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMEzjwIhnyyV",
        "outputId": "5303ce12-edea-4e9a-d3e7-f52fe561c324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input (Incomplete query): Interesting facts\n",
            "Full query: Interesting facts about Egypt \n",
            "Completion: Interesting facts about the world in which it was invented by the inventor of a?\n",
            "\n",
            "Input (Incomplete query): What is thais in phuket\n",
            "Full query: What is thais in phuket famous for \n",
            "Completion: What is thais in phuket 's surname and what does it mean to be a monk of?\n",
            "\n",
            "Input (Incomplete query): What places have the olig\n",
            "Full query: What places have the oligarchy government \n",
            "Completion: What places have the oligarchs in america and what is their role as a government of?\n",
            "\n",
            "Input (Incomplete query): Where is the radiator fan relay located at 97\n",
            "Full query: Where is the radiator fan relay located at 97 voyager \n",
            "Completion: Where is the radiator fan relay located at 97.1 miles per hour on a 2000 cherokee tah?\n",
            "\n",
            "Input (Incomplete query): When was the first\n",
            "Full query: When was the first helicopters built \n",
            "Completion: When was the first movie made in america and what did it mean to him as?\n",
            "\n",
            "Input (Incomplete query): Where is atp synthesized\n",
            "Full query: Where is atp synthesized and stored \n",
            "Completion: Where is atp synthesized in a cello-tubular system of the cells that are?\n",
            "\n",
            "Input (Incomplete query): How much chemical engineers\n",
            "Full query: How much chemical engineers are paid \n",
            "Completion: How much chemical engineers do you need to be a pediatrician in order for your job?\n",
            "\n",
            "Input (Incomplete query): What diease did jonh travoltas\n",
            "Full query: What diease did jonh travoltas son have \n",
            "Completion: What diease did jonh travoltas live in the early 's and what is his name of today?\n",
            "\n",
            "Input (Incomplete query): Give at least two diffrent descrptions of\n",
            "Full query: Give at least two diffrent descrptions of relative location \n",
            "Completion: Give at least two diffrent descrptions of the following is a good example to what kind or conditions are needed?\n",
            "\n",
            "Input (Incomplete query): What day of Diwali\n",
            "Full query: What day of Diwali in 1980 \n",
            "Completion: What day of Diwali was the holy month in china and how many people were there?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # Load fine-tuned model for testing\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('./fine_tuned_model')\n",
        "# model = GPT2LMHeadModel.from_pretrained('./fine_tuned_model')\n",
        "# model = model.to(device)\n",
        "\n",
        "test_queries = test_df['Query'][:10].tolist()\n",
        "\n",
        "for query in test_queries:\n",
        "    # tokenize and truncate input\n",
        "    input_ids_full = tokenizer(query, return_tensors='pt')\n",
        "    n = 3  # number of tokens to truncate for input\n",
        "    input_ids = input_ids_full['input_ids'][0][:-n].unsqueeze(0).to(device)\n",
        "    attention_mask = input_ids_full['attention_mask'][:, :-n].to(device)\n",
        "\n",
        "    # (played around tbh)\n",
        "    # limit len output\n",
        "    # and lower traninig samples\n",
        "    outputs = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    max_length=input_ids.shape[1] + n + 10,\n",
        "    num_return_sequences=1,  #try 3\n",
        "    no_repeat_ngram_size=2,\n",
        "    do_sample=True,\n",
        "    top_k=16,               # lower top_k: focus on most likely next tokens\n",
        "    top_p=0.5,              # lower top_p: narrow token slt\n",
        "    temperature=0.7,        # lower temp: less randomness\n",
        "    repetition_penalty=2.0  # increase to avoid repetition\n",
        "  )\n",
        "\n",
        "\n",
        "    # decode and post-process the output\n",
        "    predicted_completion = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    if not predicted_completion.endswith(\"?\"):\n",
        "        predicted_completion += \"?\"  # add ? if missing\n",
        "\n",
        "    print(f\"Input (Incomplete query): {tokenizer.decode(input_ids[0], skip_special_tokens=True)}\")\n",
        "    print(f\"Full query: {query}\")\n",
        "    print(f\"Completion: {predicted_completion}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5H4e1FoZ8lp"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Query: Interesting facts about Egypt\n",
        "Process Input (truncate last n tokens): Interesting facts ...\n",
        "Full query: Interesting facts about Egypt\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfzVYV4viIiB",
        "outputId": "842d6980-1f58-42b5-e9d3-964c02f4f9c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input (Incomplete query): Interesting facts\n",
            "Full query: Interesting facts about Egypt \n",
            "Completion: Interesting facts about the world of science fiction and fantasy writing in julian?\n",
            "\n",
            "Input (Incomplete query): What is thais in phuket\n",
            "Full query: What is thais in phuket famous for \n",
            "Completion: What is thais in phuket and how does it affect the world economy ia ica ?\n",
            "\n",
            "Input (Incomplete query): What places have the olig\n",
            "Full query: What places have the oligarchy government \n",
            "Completion: What places have the oligarchy in Greece and what is its role as a political party of?\n",
            "\n",
            "Input (Incomplete query): Where is the radiator fan relay located at 97\n",
            "Full query: Where is the radiator fan relay located at 97 voyager \n",
            "Completion: Where is the radiator fan relay located at 97.5 volts and how many miles from New York to San Francisco?\n",
            "\n",
            "Input (Incomplete query): When was the first\n",
            "Full query: When was the first helicopters built \n",
            "Completion: When was the first ever movie made and what did it mean to you see in a?\n",
            "\n",
            "Input (Incomplete query): Where is atp synthesized\n",
            "Full query: Where is atp synthesized and stored \n",
            "Completion: Where is atp synthesized in the cytoplasmic system of a cell membrane and?\n",
            "\n",
            "Input (Incomplete query): How much chemical engineers\n",
            "Full query: How much chemical engineers are paid \n",
            "Completion: How much chemical engineers are in the world today and how many people work there at a?\n",
            "\n",
            "Input (Incomplete query): What diease did jonh travoltas\n",
            "Full query: What diease did jonh travoltas son have \n",
            "Completion: What diease did jonh travoltas and his family live in the year 2000 to become a doctor or?\n",
            "\n",
            "Input (Incomplete query): Give at least two diffrent descrptions of\n",
            "Full query: Give at least two diffrent descrptions of relative location \n",
            "Completion: Give at least two diffrent descrptions of the same kind of information to be found in a newtonian?\n",
            "\n",
            "Input (Incomplete query): What day of Diwali\n",
            "Full query: What day of Diwali in 1980 \n",
            "Completion: What day of Diwali was it celebrated in japan and what year did the festival start?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # Load fine-tuned model for testing\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained('./fine_tuned_model')\n",
        "# model = GPT2LMHeadModel.from_pretrained('./fine_tuned_model')\n",
        "# model = model.to(device)\n",
        "\n",
        "test_queries = test_df['Query'][:10].tolist()\n",
        "\n",
        "for query in test_queries:\n",
        "    # tokenize and truncate input\n",
        "    input_ids_full = tokenizer(query, return_tensors='pt')\n",
        "    n = 3  # number of tokens to truncate for input\n",
        "    input_ids = input_ids_full['input_ids'][0][:-n].unsqueeze(0).to(device)\n",
        "    attention_mask = input_ids_full['attention_mask'][:, :-n].to(device)\n",
        "\n",
        "    # (played around tbh)\n",
        "    # limit len output\n",
        "    # and lower traninig samples\n",
        "    outputs = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    max_length=input_ids.shape[1] + n + 10,\n",
        "    num_return_sequences=1,  #try 3\n",
        "    no_repeat_ngram_size=2,\n",
        "    do_sample=True,\n",
        "    top_k=17,               # lower top_k: focus on most likely next tokens\n",
        "    top_p=0.5,              # lower top_p: narrow token slt\n",
        "    temperature=0.8,        # lower temp: less randomness\n",
        "    repetition_penalty=2.0 # increase to avoid repetition\n",
        "  )\n",
        "\n",
        "\n",
        "    # decode and post-process the output\n",
        "    predicted_completion = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    if not predicted_completion.endswith(\"?\"):\n",
        "        predicted_completion += \"?\"  # add ? if missing\n",
        "\n",
        "    print(f\"Input (Incomplete query): {tokenizer.decode(input_ids[0], skip_special_tokens=True)}\")\n",
        "    print(f\"Full query: {query}\")\n",
        "    print(f\"Completion: {predicted_completion}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R93H3Z7HsfrY"
      },
      "source": [
        "# Try to remove the trailing of the open-ended outputs\n",
        "\n",
        "- Currently doesn't seem much better. It removed trailings but doesn't provide suggestions for other inputs\n",
        "- Needs further work\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqKRxI-W0KDC",
        "outputId": "651a6962-437e-459b-a8fd-779d6798f4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input (Incomplete query): Interesting facts\n",
            "Full query: Interesting facts about Egypt \n",
            "Completion: Interesting facts about the world in australia?\n",
            "\n",
            "Input (Incomplete query): What is thais in phuket\n",
            "Full query: What is thais in phuket famous for \n",
            "Completion: What?\n",
            "\n",
            "Input (Incomplete query): What places have the olig\n",
            "Full query: What places have the oligarchy government \n",
            "Completion: What places have the oligarchy in czech republics?\n",
            "\n",
            "Input (Incomplete query): Where is the radiator fan relay located at 97\n",
            "Full query: Where is the radiator fan relay located at 97 voyager \n",
            "Completion: Where?\n",
            "\n",
            "Input (Incomplete query): When was the first\n",
            "Full query: When was the first helicopters built \n",
            "Completion: When?\n",
            "\n",
            "Input (Incomplete query): Where is atp synthesized\n",
            "Full query: Where is atp synthesized and stored \n",
            "Completion: Where?\n",
            "\n",
            "Input (Incomplete query): How much chemical engineers\n",
            "Full query: How much chemical engineers are paid \n",
            "Completion: How much chemical engineers make a year in the US?\n",
            "\n",
            "Input (Incomplete query): What diease did jonh travoltas\n",
            "Full query: What diease did jonh travoltas son have \n",
            "Completion: What diease did jonh travoltas?\n",
            "\n",
            "Input (Incomplete query): Give at least two diffrent descrptions of\n",
            "Full query: Give at least two diffrent descrptions of relative location \n",
            "Completion: Give at least two diffrent descrptions of the term \"bioluminescent\" in?\n",
            "\n",
            "Input (Incomplete query): What day of Diwali\n",
            "Full query: What day of Diwali in 1980 \n",
            "Completion: What day of Diwali?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_queries = test_df['Query'][:10].tolist()\n",
        "\n",
        "import re\n",
        "\n",
        "def clean_completion(completion):\n",
        "    # hardcode rm trailing\n",
        "    completion = re.sub(r'\\b(and|what|how|does|is|was|to|by)\\b.*$', '', completion).strip()\n",
        "    return completion\n",
        "\n",
        "\n",
        "for query in test_queries:\n",
        "    # tokenize and truncate input\n",
        "    input_ids_full = tokenizer(query, return_tensors='pt')\n",
        "    n = 3  # number of tokens to truncate for input\n",
        "    input_ids = input_ids_full['input_ids'][0][:-n].unsqueeze(0).to(device)\n",
        "    attention_mask = input_ids_full['attention_mask'][:, :-n].to(device)\n",
        "\n",
        "\n",
        "    outputs = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    max_length=input_ids.shape[1] + 10,  # changed here (remove +n)\n",
        "    num_return_sequences=2,\n",
        "    no_repeat_ngram_size=2,\n",
        "    do_sample=True,\n",
        "    top_k=20,               # lower top_k to focus on most likely next tokens\n",
        "    top_p=0.8,              # lower top_p to further narrow token slt\n",
        "    temperature=0.5,        # lower temp for less randomness\n",
        "    repetition_penalty=2.0  # increase penalty to avoid repetition\n",
        "  )\n",
        "\n",
        "    # decode and post-process the output\n",
        "    predicted_completion = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    predicted_completion = clean_completion(predicted_completion)\n",
        "\n",
        "    if not predicted_completion.endswith(\"?\"):\n",
        "        predicted_completion += \"?\"  # add ? if missing\n",
        "\n",
        "    print(f\"Input (Incomplete query): {tokenizer.decode(input_ids[0], skip_special_tokens=True)}\")\n",
        "    print(f\"Full query: {query}\")\n",
        "    print(f\"Completion: {predicted_completion}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBLo0oA_tfrA"
      },
      "source": [
        "# V3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxojsTAJu_J8"
      },
      "source": [
        "a silly output of this version\n",
        "\n",
        "\n",
        "- Input (Incomplete query): How much chemical engineers\n",
        "- Full query: How much chemical engineers are paid\n",
        "- Completion: How much chemical engineers do in the US  and how many are there on earth?\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
